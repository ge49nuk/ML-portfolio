misc:
  exp_dir: poseverse
  gpu_mode: True
  verbose: True
  verbose_freq: 25
  mode: train

model:
  pretrain: ''
  transformer_architecture: ['self', 'cross', 'self', 'cross', 'self', 'cross']
  with_cross_pos_embed: True

optim:
  optimizer: ADAM
  lr: 0.0001
  weight_decay: 0.000001
  momentum: 0.98
  scheduler: ExpLR
  scheduler_gamma: 0.999999
  iter_size: 1

data:
  dataset: bop 
  benchmark: BOP
  train_val_split: 0.9
  root: /dl/volatile/students/projects/multi_mod_dl/dataset 
  data_augmentation: True
  min_visib_fract: 0.4

coarse_matching:
  matching_radius: 0.07
  num_gt_coarse_corr: 128
  num_est_coarse_corr: 256
  coarse_overlap_threshold: 0.1 

fine_matching:
  point_per_patch: 64
  fine_matching_topk: 3
  fine_matching_mutual: True
  fine_matching_confidence_threshold: 0.05
  fine_matching_use_dustbin: False
  fine_matching_use_global_score: False
  fine_matching_correspondence_threshold: 0.005

coarse_loss:
  coarse_loss_positive_margin: 0.1
  coarse_loss_negative_margin: 1.4
  coarse_loss_positive_optimal: 0.1
  coarse_loss_negative_optimal: 1.4
  coarse_loss_log_scale: 24
  coarse_loss_positive_overlap: 0.1
  coarse_loss_weight: 1.0

fine_loss:
  fine_loss_positive_radius: 0.07
  fine_loss_weight: 1.0

occlusion_loss:
  occ_loss_weight: 0.0

eval:
  eval_acceptance_overlap: 0.0
  eval_acceptance_radius: 0.07

train:
  max_epoch: 1000
  batch_size: 1
  training_max_iter: 3500
  val_max_iter: 500
  scheduler_interval: 1
  snapshot_interval: 500
  num_workers: 8
  val_every_n_epoch: 1
