# Managed by Hydra

ckpt_path: null
augs_per_scene: 16
num_descriptions: 20
samples_per_proposal: 48
disturbation_start_epoch: 50

logger:
  # https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html
  _target_: pytorch_lightning.loggers.WandbLogger
  project: ${model.network.module}
  name: ${experiment_name}

# https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
trainer:
  accelerator: gpu
  devices: auto
  strategy: ddp_find_unused_parameters_true
  num_nodes: 1
  max_epochs: 220
  num_sanity_val_steps: 5
  check_val_every_n_epoch: 5
  profiler: simple

# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html
checkpoint_monitor:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  save_top_k: -1
  every_n_epochs: 5 #${model.trainer.check_val_every_n_epoch}
  filename: "{epoch}"
  dirpath: ${exp_output_root_path}/training


inference:
  split: val
  evaluate: False
  save_predictions: True

log:
  WandbLogger:
    project: Joint_Light
    name: ${experiment_name}
  TensorBoardLogger:
    name: Joint_Light

optimizer:
    _target_: torch.optim.Adam
    lr: 1e-4
    
network:
  module: Joint_Light

